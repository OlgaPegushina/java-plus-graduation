# Explore With Me (Микросервисная версия)

**Explore With Me** — это бэкенд-сервис для афиши событий, где пользователи могут находить интересные мероприятия, создавать свои собственные и участвовать в них. Проект реализован на основе современной микросервисной архитектуры с использованием **Spring Cloud**.

---

## Архитектура проекта

Проект построен на принципах микросервисной архитектуры для обеспечения гибкости, масштабируемости и отказоустойчивости. Ключевые компоненты экосистемы Spring Cloud играют центральную роль во взаимодействии сервисов.

#### Компоненты инфраструктуры

*   **Config Server** (`config-server`): Централизованное хранилище конфигураций для всех микросервисов. Позволяет изменять настройки приложений без их перезапуска.
*   **Discovery Server (Eureka)** (`discovery-server`): Сервис обнаружения. Каждый микросервис при запуске регистрируется в Eureka, что позволяет им динамически находить друг друга по имени.
*   **API Gateway** (`gateway-server`): Единая точка входа для всех внешних запросов. Отвечает за маршрутизацию, а также может выполнять задачи аутентификации, логирования и ограничения скорости запросов.

#### Бизнес-микросервисы

*   **Event Service** (`event-service`): Основной сервис, отвечающий за всю бизнес-логику, связанную с событиями, категориями и подборками.
*   **User Service** (`user-service`): Отвечает за управление пользователями (создание, получение данных, обновление, удаление).
*   **Request Service** (`request-service`): Отвечает за управление запросами на участие в событиях (создание, подтверждение, отклонение).
*   **Comment Service** (`comment-service`): Сервис для управления комментариями к событиям.
*   **Statistics Service** (`stats-server`): Сервис для сбора и предоставления статистики по просмотрам событий.

### Сервисы обработки данных и рекомендаций (Новые компоненты)

Новая часть системы отвечает за сбор, агрегацию и анализ пользовательских действий для генерации рекомендаций.

*   **Collector Service (`collector-service`):**
    *   **Назначение:** Является первым узлом обработки входящих пользовательских действий. Получает сырые данные о действиях (например, просмотры, лайки, регистрации) от других сервисов (например, `event-service`) через gRPC.
    *   **Технологии:** gRPC (для приема данных), Avro (для сериализации данных при отправке в Kafka), Kafka Producer.
    *   **Взаимодействие:** Принимает данные через gRPC, преобразует их в формат Avro и отправляет в Kafka для дальнейшей обработки.

*   **Aggregator Service (`aggregator-service`):**
    *   **Назначение:** Обрабатывает поток пользовательских действий из Kafka. Агрегирует веса действий для каждого пользователя и события, пересчитывает матрицу схожести событий.
    *   **Технологии:** Kafka Consumer (Avro), Java (Spring), `HashMap` (для хранения весов и матриц схожести)
    *   **Взаимодействие:** Читает данные из Kafka, обновляет внутренние структуры данных.

*   **Analyzer Service (`analyzer-service`):**
    *   **Назначение:** Этот сервис отвечает за финальный расчет рекомендаций на основе данных, подготовленных `aggregator-service`, и предоставление их другим сервисам (например, `event-service`) через gRPC.
    *   **Технологии:** gRPC (как сервер для предоставления рекомендаций), Java (Spring), Protobuf (для определения gRPC-сервисов и сообщений).
    *   **Взаимодействие:** Предоставляет API через gRPC, чтобы другие сервисы (например, `event-service`, который управляет API для фронтенда) могли запрашивать персонализированные рекомендации для пользователей или похожие события.

#### Хранение данных (Database per Service)

*Каждый бизнес-микросервис имеет свою собственную, изолированную базу данных* **PostgreSQL**. Этот подход является ключевым для микросервисной архитектуры, так как обеспечивает слабую связанность (*loose coupling*) между сервисами. Один сервис не может напрямую получить доступ к таблицам другого. Все взаимодействие происходит исключительно через API.

#### Схема взаимодействия

Взаимодействие между сервисами происходит через REST API (Feign) или gRPC.. Для межсервисной коммуникации используется декларативный клиент **Feign**, который интегрирован с Eureka для динамического обнаружения нужного сервиса, а также gRPC клиенты

*   **Внешние запросы:** Поступают на `API Gateway`.

*   **REST API (Feign):** Бизнес-сервисы (например, `event-service`) используют `Feign` для взаимодействия друг с другом, полагаясь на `Eureka` для обнаружения.

*   **gRPC:**
    *   `Collector Service` принимает данные о действиях через gRPC в формате Proto от `event-service` (или других источников).
    *   `Aggregator Service` читает данные из Kafka (в формате Avro) и отправляет дальше для получения/отправки данных, необходимых для `analizer-service`.
    *   `Analyzer Service` предоставляет API через gRPC, чтобы другие сервисы (например, `event-service`) могли запрашивать рекомендации.
---

## Технологический стек

*   **Язык**: Java 21
*   **Фреймворк**: Spring Boot 3.x
*   **Spring Cloud**:
    *   *Spring Cloud Gateway*: для API-шлюза.
    *   *Spring Cloud Netflix Eureka*: для Service Discovery.
    *   *Spring Cloud Config Server*: для централизованной конфигурации.
    *   *Spring Cloud OpenFeign*: для декларативных REST-клиентов.
*   **База данных**: PostgreSQL (схема "Database per Service").
*   **ORM**: Spring Data JPA, Hibernate.
*   **Сборка проекта**: Maven.
*   **Контейнеризация**: Docker, Docker Compose.
*   **Коммуникации**:
*   *   *gRPC:* Для высокопроизводительной межсервисной коммуникации (`Collector`, `Aggregator`, `Analyzer`, `Event Service`).
*   *   *Protobuf:* Формат сериализации для gRPC.
*   *   *Avro:* Формат сериализации для сообщений `Kafka`.
*   *   *Kafka:* Асинхронный брокер сообщений для передачи данных о действиях.
*   **Вспомогательные библиотеки**:
    *   `Lombok` (для сокращения шаблонного кода).
    *   `QueryDSL` (для типобезопасных запросов).
    *   `MapStruct` (для маппинга DTO).

---

## Основные возможности (API)
Проект предоставляет три типа эндпоинтов, доступ к которым осуществляется через API Gateway

#### Публичные (Public API)
*   Просмотр событий с фильтрацией и сортировкой.
*   Просмотр категорий и подборок событий.
*   Получение комментариев к событию.
*   Получение рекомендаций для пользователя (через gRPC-вызов к Analyzer Service, инициированный Event Service). 

#### Приватные (Private API)
*   Создание, редактирование и просмотр своих событий.
*   Отправка, просмотр и отмена своих запросов на участие.
*   Управление статусами заявок на участие в своих событиях.
*   Добавление, редактирование и удаление своих комментариев.

#### Админские (Admin API)
*   Управление пользователями (создание, просмотр, обновление, удаление).
*   Управление категориями, событиями и подборками.
*   Модерация событий и комментариев.

---

## Пример использования API
После запуска вы можете отправлять запросы к сервису через Gateway.

**Пример: Получение полной информации о событии**

1.  Клиент отправляет запрос на Gateway: `GET /events/1`.
2.  Gateway перенаправляет запрос на **Event Service**.
3.  Event Service находит в своей базе данных событие с `id=1`. В этом событии есть поле `initiatorId`.
4.  Чтобы обогатить ответ полными данными об инициаторе, **Event Service** через свой Feign-клиент отправляет внутренний запрос `GET /admin/users/123` (где `123` - это `initiatorId`) к **User Service**.
5.  User Service отвечает данными пользователя.
6.  Event Service собирает полную DTO события, включая данные об инициаторе, и возвращает клиенту.

**Пример: Получение рекомендаций для пользователя**

1.  Клиент (или другой сервис) запрашивает рекомендации для `userId=123` у `Event Service` (например, через REST API).
2.  `Event Service` (выступая как gRPC-клиент) обращается к `Analyzer Service` с запросом на получение рекомендаций для `userId=123`.
3.  `Analyzer Service` (который имеет доступ к данным, рассчитанным `Aggregator Service`) возвращает список рекомендованных событий.
4.  `Event Service` получает этот список и возвращает его клиенту.
---

## Автор
*   **Имя:** Ольга
*   **Email:** pegushina.shine@yandex.ru
*   **Telegram:** @TheSunOfSpring
